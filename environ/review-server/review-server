#! /usr/bin/env python
# -*- coding: utf-8 -*-

# No Copyright (-) 2010 The Ampify Authors. This file is under the
# Public Domain license that can be found in the root LICENSE file.

"""Git review server."""

import logging
import sys

from base64 import urlsafe_b64encode
from binascii import hexlify
from cgi import escape
from datetime import datetime, timedelta
from hashlib import md5
from hmac2 import HMAC
from optparse import OptionParser
from os import chdir, close, environ, getcwd, remove, urandom, write
from os.path import dirname, isdir, join, realpath
from re import compile as compile_regex, DOTALL, MULTILINE
from Queue import Queue
from shutil import rmtree
from tempfile import mkstemp
from thread import start_new_thread
from time import sleep
from urllib import quote, unquote_plus, urlencode, urlopen

from tornado.httpserver import HTTPServer
from tornado.options import enable_pretty_logging
from tornado.web import Application, HTTPError, RequestHandler
from tornado.ioloop import IOLoop

from markdown import markdown
from pyutil.async import async as process
from pyutil.crypto import create_tamper_proof_string, secure_string_comparison
from pyutil.env import run_command
from pyutil.io import IteratorParser
from pyutil.redis import Redis, set_max_connections
from pyutil.sanitise import sanitise
from simplejson import loads as decode_json, dumps as encode_json
from yaml import safe_load as decode_yaml

# ------------------------------------------------------------------------------
# Import Path
# ------------------------------------------------------------------------------

AMPIFY_ROOT = dirname(dirname(dirname(realpath(__file__))))
APP_ENGINE_SDK_PATH = join(AMPIFY_ROOT, '.appengine_python_sdk')

sys.path.insert(0, APP_ENGINE_SDK_PATH)
sys.path.insert(0, join(APP_ENGINE_SDK_PATH, 'lib', 'webob'))
sys.path.insert(0, join(APP_ENGINE_SDK_PATH, 'lib', 'fancy_urllib'))

from google.appengine.api import apiproxy_stub_map
from google.appengine.tools.appengine_rpc import HttpRpcServer
from google.appengine.ext import db
from google.appengine.ext.remote_api.remote_api_stub import (
    GetSourceName, GetUserAgent, RemoteDatastoreStub, RemoteStub
    )

class NonAuthHttpRpcServer(HttpRpcServer):
    def _DevAppServerAuthenticate(self):
        pass

# ------------------------------------------------------------------------------
# Settings
# ------------------------------------------------------------------------------

settings = dict(
    cookie_secret='insecure',
    debug=False,
    login_url='/login',
    port=8090,
    redis_socket_file='/tmp/review-server-cache.sock',
    repos=None,
    static_path='static',
    template_path='templates',
    var_path='var',
    xsrf_cookies=False
    )

Loop = IOLoop.instance()

repos = {}
repo_paths = {}
repo_cache = {}
repo_commits = {}
repo_maintainers = {}
maintainer_repos = {}

cache = None
caches = {}
secure_id_prefix = hexlify(urandom(18))

review_stages = {
    'pending': '<span class="subdued">needs "safe to build"</span>',
    'build': '<span class="subdued">awaiting builds</span>',
    'built': 'built',
    'approved': '✓',
    'applied': '✓✓',
    'rejected': '<span class="grey">✗</span>'
    }

# ------------------------------------------------------------------------------
# Cache
# ------------------------------------------------------------------------------

Blank = object()

class CachingDict(dict):
    """A caching dict that discards its least recently used items."""

    __slots__ = (
        '_cache_size', '_garbage_collector', '_buffer_size', 'itersort',
        '_clock'
        )

    def __init__(
        self, cache_size=10000, buffer_size=None, garbage_collector=None, *args,
        **kwargs
        ):

        self._cache_size = cache_size
        self._garbage_collector = garbage_collector
        self._buffer_size = buffer_size or cache_size / 2
        self._clock = 0

        for key, value in args:
            self.__setitem__(key, value)

        for key, value in kwargs.iteritems():
            self.__setitem__(key, value)

    def __setitem__(self, key, value):
        excess = len(self) - self._cache_size - self._buffer_size + 1
        if excess > 0:
            garbage_collector = self._garbage_collector
            # @@ time against : heapq.nsmallest()
            excess = sorted(self.itersort())[:excess + self._buffer_size]
            for ex_value, ex_key in excess:
                if garbage_collector:
                    garbage_collector(ex_key, ex_value)
                del self[ex_key]

        self._clock += 1
        return dict.__setitem__(self, key, [self._clock, value])

    def __getitem__(self, key):
        if key in self:
            access = dict.__getitem__(self, key)
            self._clock += 1
            access[0] = self._clock
            return access[1]

        raise KeyError(key)

    def itersort(self):
        getitem = dict.__getitem__
        for key in self:
            yield getitem(self, key), key

    def get(self, key, default=None):
        if key in self:
            return self.__getitem__(key)
        return default

    def pop(self, key, default=Blank):

        if key in self:
            value = dict.__getitem__(self, key)[1]
            del self[key]
            return value

        if default is not Blank:
            return default

        raise KeyError(key)

    def setdefault(self, key, default):
        if key in self:
            return self.__getitem__(key)
        self.__setitem__(key, default)
        return default

    def itervalues(self):
        getitem = self.__getitem__
        for key in self:
            yield getitem(key)

    def values(self):
        return list(self.itervalues())

    def iteritems(self):
        getitem = self.__getitem__
        for key in self:
            yield key, getitem(key)

    def items(self):
        return list(self.iteritems())

    def set_cache_size(self, cache_size):
        if not isinstance(cache_size, (int, long)):
            raise ValueError("Cache size must be an integer.")
        self._cache_size = cache_size

    def get_cache_byte_size(self):
        getitem = self.__getitem__
        return sum(len(str(getitem(key))) for key in self)

# ------------------------------------------------------------------------------
# Threaded Workers
# ------------------------------------------------------------------------------

URL_QUEUE = Queue()
GIT_QUEUE = Queue()
GAE_QUEUE = Queue()

EVENTS = {}

def get_cache_key(func, args, kwargs):
    return (func.__name__,) + args + tuple(sorted(kwargs.values()))

def invalidate(*names):
    for name in names:
        if name not in caches:
            continue
        caches[name].clear()

def threaded_worker_dispatcher(queue, error_logger=None):
    while 1:
        marker, worker, args, kwargs = queue.get()
        try:
            response = worker(*args, **kwargs)
        except Exception, error:
            EVENTS[marker] = (1, error)
        else:
            EVENTS[marker] = (0, response)

class Worker(object):

    def __init__(self, queue, callback, errback, func, args, kwargs, cache):
        self.marker = marker = id(self)
        self.cache = cache
        self.callback = callback
        self.errback = errback
        if cache:
            if cache not in caches:
                caches[cache] = CachingDict(5000)
            cache_store = caches[cache]
            cache_key = get_cache_key(func, args, kwargs)
            cached_data = cache_store.get(cache_key, Blank)
            self.cache_key = cache_key
            if cached_data is not Blank:
                EVENTS[marker] = (0, cached_data)
                Loop.add_callback(self.respond)
                return
        queue.put((marker, func, args, kwargs))
        Loop.add_callback(self.respond)

    def respond(self):
        marker = self.marker
        if marker not in EVENTS:
            Loop.add_callback(self.respond)
            return
        error, response = EVENTS.pop(marker)
        if error:
            self.errback(response)
        else:
            cache = self.cache
            if cache:
                caches[cache][self.cache_key] = response
            self.callback(response)

def worker(queue, cache=None):
    def __worker(func):
        def wrapper(*args, **kwargs):
            def __wrapper(callback, errback):
                return Worker(
                    queue, callback, errback, func, args, kwargs, cache
                    )
            __wrapper.__name__ = func.__name__
            return __wrapper
        wrapper.__name__ = func.__name__
        return wrapper
    return __worker

# ------------------------------------------------------------------------------
# Async Support
# ------------------------------------------------------------------------------

class TornadoWebDispatcher(object):
    """An async process dispatcher for tornado web handler methods."""

    cb = None

    def __init__(self, gen, handler):
        self.gen = gen
        self.handler = handler
        self.callback(None)

    def callback(self, arg=None, errback=None):
        try:
            if self.cb:
                self.cb(callback=self.callback, errback=self.errback)
                self.cb = None
                return
            if errback:
                self.cb = self.gen.throw(arg)
            else:
                self.cb = self.gen.send(arg)
            Loop.add_callback(self.callback)
        except StopIteration:
            self.cb = None
            if not self.handler._finished:
                self.handler.finish()
        except Exception, error:
            self.cb = None
            if self.handler._headers_written:
                logging.error('Exception after headers written', exc_info=True)
            else:
                self.handler._handle_request_exception(error)

    def errback(self, arg):
        self.callback(arg, errback=1)

def async(method):
    def wrapper(handler, *args, **kwargs):
        handler._auto_finish = 0
        TornadoWebDispatcher(method(handler, *args, **kwargs), handler)
    wrapper.__name__ = method.__name__
    return wrapper

# ------------------------------------------------------------------------------
# Auth Support
# ------------------------------------------------------------------------------

def auth(async=True, cookie=True, xsrf=True):
    def wrapper(method):
        def __wrapper(handler, *args, **kwargs):
            handler._auto_finish = 0
            TornadoWebDispatcher(
                authenticate(
                    async, method, handler, cookie, xsrf, *args, **kwargs
                    ),
                handler
                )
        __wrapper.__name__ = method.__name__
        return __wrapper
    return wrapper

def authenticate(async, method, handler, cookie, xsrf, *args, **kwargs):
    login = handler.get_argument('login', '')
    if login:
        token = handler.get_argument('token', '')
        if login in USERS:
            if not secure_string_comparison(USERS[login], token):
                raise HTTPError(403)
        info = yield get_github_user_info(login, token)
        if not info:
            raise HTTPError(403)
        yield update_user(login, info)
    elif cookie:
        login = handler.get_secure_cookie('login')
        if not login:
            handler.redirect('/login')
            return
        if xsrf:
            xsrf_token = handler.get_argument('xsrf_token', '')
            if not xsrf_token:
                raise HTTPError(403)
            if login not in XSRF:
                XSRF[login] = HMAC(settings['xsrf_secret'], login).hexdigest()
            if not secure_string_comparison(XSRF[login], xsrf_token):
                raise HTTPError(403)
    else:
        raise HTTPError(403)
    if async:
        gen = method(handler, *args, **kwargs)
        resp = None
        # @@ this pipelining doesn't support catching exceptions downstream
        while 1:
            resp = yield gen.send(resp)
    else:
        method(handler, *args, **kwargs)

# ------------------------------------------------------------------------------
# Utility Functions
# ------------------------------------------------------------------------------

def git(*args, **kwargs):
    if kwargs.pop('raise_error', None):
        kwargs['retcode'] = True
        kwargs['reterror'] = True
        args = ['git'] + list(args)
        logging.info("Running: %s" % ' '.join(args))
        stdout, stderr, retcode = run_command(args, **kwargs)
        if retcode:
            raise RuntimeError(
                "Error running %s cwd=%s\n\n%s\n%s"
                % (' '.join(args), getcwd(), stdout, stderr)
                )
        return stdout
    if kwargs.pop('out', None):
        if 'exit_on_error' not in kwargs:
            kwargs['exit_on_error'] = True
        kwargs['redirect_stdout'] = False
        kwargs['redirect_stderr'] = False
        kwargs['retcode'] = True
    return run_command(['git'] + list(args), **kwargs)

def valid_patch_name(id, valid=set('abcdefghijklmnopqrstuvwxyz0123456789.-_')):
    if id.startswith('-') or id.startswith('_'):
        return
    for char in id:
        if char not in valid:
            return
    return 1

def is_repo_dev(repo_name, user):
    maintainer = repo_maintainers.get(repo_name, None)
    if not maintainer:
        return
    if user == maintainer:
        return True
    repo = repo_cache.get(repo_name, None)
    if repo and repo.core_devs:
        if user in repo.core_devs:
            return True

def get_difference(s1, s2, encoded=0):
    try:
        u1 = unicode(s1, 'utf-8')
        u2 = unicode(s2, 'utf-8')
    except Exception:
        pass
    else:
        s1, s2 = u1, u2
        encoded = 1
    head = 0
    for left, right in zip(s1, s2[:len(s1)]):
        if left != right:
            break
        head += 1
    tail = 0
    for left, right in zip(reversed(s1[head:]), s2[-1:-len(s1)-head-1:-1]):
        if left != right:
            break
        tail -= 1
    if not tail:
        if encoded:
            return s1[:head].encode('utf-8'), s1[head:].encode('utf-8'), ''
        return s1[:head], s1[head:], ''
    if encoded:
        return (
            s1[:head].encode('utf-8'),
            s1[head:tail].encode('utf-8'),
            s1[tail:].encode('utf-8')
            )
    return s1[:head], s1[head:tail], s1[tail:]

# GitHub-flavoured markdown port adapted from http://gist.github.com/457617
replace_newlines = compile_regex(r'^[\w\<][^\n]*(\n+)', MULTILINE).sub
pre_extract = compile_regex(r'<pre>.*?</pre>', MULTILINE | DOTALL).sub
pre_insert = compile_regex(r'{gfm-extraction-([0-9a-f]{32})\}').sub

def gfm(text):
    # Extract pre blocks.
    extractions = {}
    def pre_extraction_callback(matchobj):
        digest = md5(matchobj.group(0) + str(len(extractions))).hexdigest()
        extractions[digest] = matchobj.group(0)
        return "{gfm-extraction-%s}" % digest
    text = pre_extract(pre_extraction_callback, text)
    # In very clear cases, let newlines become <br /> tags.
    def newline_callback(matchobj):
        if len(matchobj.group(1)) == 1:
            return matchobj.group(0).rstrip() + '  \n'
        else:
            return matchobj.group(0)
    text = replace_newlines(newline_callback, text)
    # Insert pre block extractions.
    def pre_insert_callback(matchobj):
        return '\n\n' + extractions[matchobj.group(1)]
    return pre_insert(pre_insert_callback, text)

css_classes = set([
    'c', 'cm', 'cp', 'cs', 'c1', 'err', 'g', 'gd', 'ge', 'gh', 'gi',
    'go', 'gp', 'gr', 'gs', 'gt', 'gu', 'k', 'kc', 'kd', 'kn', 'kp',
    'kr', 'kt', 'l', 'ld', 'm', 'mf', 'mh', 'mi', 'il', 'mo', 'bp',
    'n', 'na', 'nb', 'nc', 'nd', 'ne', 'nf', 'ni', 'nl', 'nn', 'no',
    'nx', 'nt', 'nv', 'vc', 'vg', 'vi', 'py', 'o', 'ow', 'p', 's',
    'sb', 'sc', 'sd', 'se', 'sh', 'si', 'sr', 'ss', 'sx', 's1', 's2',
    'w', 'x', 'css', 'rst', 'bash', 'yaml', 'codehilite'
    ])

def render_text(text, css_classes=css_classes):
    if not isinstance(text, unicode):
        try:
            text = text.decode('utf-8')
        except UnicodeDecodeError:
            return "ERROR: text encoding."
    return sanitise(
        markdown(gfm(text), ['codehilite']), secure_id_prefix=secure_id_prefix,
        valid_css_classes=css_classes
        )

def get_gravatar(user):
    if not user:
        return
    gravatar = GRAVATARS.get(user)
    if gravatar:
        return gravatar
    NEEDED_GRAVATARS.add(user)

# ------------------------------------------------------------------------------
# Worker Functions
# ------------------------------------------------------------------------------

USERS = CachingDict()
XSRF = CachingDict()
EMAILS = CachingDict()
GRAVATARS = CachingDict()
USERS2EMAILS = CachingDict()
NEEDED_GRAVATARS = set()

@worker(URL_QUEUE)
def get_github_user_info(login, token, keys=['email', 'gravatar_id', 'name']):
    info = dict(login=login, token=token)
    url = "http://github.com/api/v2/json/user/show/%s?%s" % (
        quote(login), urlencode(info)
        )
    try:
        data = decode_json(urlopen(url).read())['user']
    except Exception:
        return
    if 'plan' not in data:
        return
    for key in keys:
        if key in data:
            info[key] = data[key]
    USERS[login] = token
    EMAILS[info['email']] = login
    # USERS2EMAILS[login] = '"%s" <%s>' % (info.get('name', login), info['email'])
    USERS2EMAILS[login] = info['email']
    GRAVATARS[login] = info['gravatar_id']
    return info

GAE_SERVICES = [
    'capability_service',
    'images',
    'mail',
    'memcache',
    'taskqueue',
    'urlfetch',
    'xmpp'
]

def _init_appengine(app_id, host, remote_key, secure, services=GAE_SERVICES):

    verifier = urlsafe_b64encode(urandom(24))
    mac = create_tamper_proof_string(
        'remote', verifier, duration=None, key=remote_key
        )

    path = '/.remote/%s' % mac
    environ['APPLICATION_ID'] = app_id

    server = NonAuthHttpRpcServer(
        host, None, GetUserAgent(), GetSourceName(), debug_data=False,
        secure=secure
        )

    apiproxy_stub_map.apiproxy = apiproxy_stub_map.APIProxyStubMap()
    datastore_stub = RemoteDatastoreStub(server, path)
    apiproxy_stub_map.apiproxy.RegisterStub('datastore_v3', datastore_stub)

    stub = RemoteStub(server, path)
    for service in services:
        apiproxy_stub_map.apiproxy.RegisterStub(service, stub)

def init_appengine(*args, **kwargs):
    marker = id(init_appengine)
    GAE_QUEUE.put((marker, _init_appengine, args, kwargs))
    while 1:
        if marker in EVENTS:
            break
        sleep(0.4)
    error, response = EVENTS.pop(marker)
    if error:
        raise response

def setup_repo_platforms(repo):
    if not repo.platforms:
        repo._platforms = []
        repo._unames = {}
        repo_cache[repo.key().name()] = repo
        return
    repo._unames = unames = decode_yaml(repo.platforms)
    repo._platforms = platforms = []
    if unames and isinstance(unames, dict):
        for platform in unames.values():
            if platform not in platforms:
                platforms.append(platform)
    else:
        repo._unames = {}
    repo_cache[repo.key().name()] = repo

@worker(GAE_QUEUE)
def update_repo(repo, platforms, core_devs):
    repo_obj = Repo.get_by_key_name(repo)
    repo_obj.platforms = platforms.strip()
    repo_obj.core_devs = filter(None, core_devs.strip().splitlines())
    repo_obj.put()
    setup_repo_platforms(repo_obj)

@worker(GAE_QUEUE, cache='slaves:auth')
def get_authorised_slaves(repo):
    return Slave.all().filter('a =', repo).order('__key__').fetch(1000)

@worker(GIT_QUEUE)
def apply_patch(repo, review_id, upstream, patch_file):
    chdir(repo_paths[repo])
    git('remote', 'update', '-p', 'upstream', raise_error=True)
    git('am', '--abort')
    git('rebase', '--abort')
    git('clean', '-fdx', raise_error=True)
    git('reset', '--hard', 'HEAD', raise_error=True)
    for path in git('status', '--porcelain', raise_error=True).splitlines():
        if path.startswith('??'):
            path = path.split('??', 1)[1].strip()
            if isdir(path):
                rmtree(path)
    git('checkout', '-b', review_id, upstream, raise_error=True)
    git('am', patch_file, raise_error=True)
    git('push', 'origin', 'upstream/master:master', review_id, raise_error=True)

class Retry(Exception):
    pass

def _update_and_email_review(base_key, review, cc, expected, emails):
    base = db.get(base_key)
    if not base.cc == expected:
        raise Retry("It's changed!")
    for person in cc:
        if person not in base.cc:
            base.cc.append(person)
    db.put([base, review])

@worker(GAE_QUEUE)
def update_and_email_review(base, review, cc, n=3):
    while n:
        if base.cc:
            expected_cc = base.cc[:]
        else:
            expected_cc = []
        likely_cc = cc.union(expected_cc)
        needed_emails = []; needed = needed_emails.append
        emails = set()
        skipped = []
        for person in likely_cc:
            if '@' in person:
                emails.add(person)
            else:
                email = USERS2EMAILS.get(person, None)
                if email:
                    emails.add(email)
                else:
                    needed(person)
        if needed_emails:
            users = User.get_by_key_name(needed_emails)
            for idx, user in enumerate(users):
                if user:
                    login = needed_emails[idx]
                    # email = '"%s" <%s>' % (user.name or login, user.email)
                    email = user.email
                    USERS2EMAILS[login] = email
                    emails.add(email)
                else:
                    skipped.append(needed_emails[idx])
        try:
            db.run_in_transaction(
                _update_and_email_review, base.key(), review, cc,
                expected_cc, emails
                )
        except Retry:
            n -= 1
            continue
        if skipped:
            logging.error("Couldn't email %s" % skipped)
        return

def _get_review_object(base_key, repo, revision, result, create_key=db.Key.from_path):
    base = ReviewBase.get(base_key)
    if not base:
        base = ReviewBase(key=base_key)
        base.repo = repo
    base.latest += 1
    review = Review(key_name=str(base.latest), parent=base_key)
    review.revision = revision
    db.put([base, review])
    result.append([base, review])

@worker(GAE_QUEUE)
def get_review_object(repo, user, patch_name, revision):
    exist = Review.all().filter('r =', repo).filter('z =', revision).get()
    if exist:
        return 1, exist.version
    base_key = db.Key.from_path('Q', '%s:%s:%s' % (repo, user, patch_name))
    result = []
    db.run_in_transaction(_get_review_object, base_key, repo, revision, result)
    if result:
        return result[0]

def _get_new_commits(repo, start):
    chdir(repo_paths[repo])
    git('remote', 'update', '-p', 'upstream', raise_error=True)
    git('push', 'origin', 'upstream/master:master', raise_error=True)
    return filter(None, [commit.strip().splitlines() for commit in git(
        'log', '--format=%H%n%an%n%ae%n%at%n%cn%n%ce%n%ct%n%s%x00',
        '--no-color', '%s...upstream/master' % start, raise_error=True
        ).split('\x00')])

get_new_commits = worker(GIT_QUEUE)(_get_new_commits)

def _create_commits(repo, data):
    commits = []; new_commit = commits.append
    first = 1
    for (rev, an, ae, at, cn, ce, ct, subject) in data:
        if first:
            first = 0
            repo_commits[repo] = rev
        commit = Commit.get_or_insert('%s:%s' % (repo, rev))
        if commit.version:
            continue
        commit.version = rev
        commit.author = an
        commit.author_email = ae
        commit.committer = cn
        commit.committer_email = ce
        commit.d = datetime.fromtimestamp(int(ct))
        commit.repo = repo
        commit.subject = subject
        if ae:
            if ae in EMAILS:
                commit.user = EMAILS[ae]
            else:
                user = User.all().filter('e =', ae).get()
                if user:
                    user = user.key().name()
                    EMAILS[ae] = user
                    commit.user = user
                else:
                    commit.user = ''
        else:
            commit.user = ''
        commit.needed_builds = repo_cache[repo]._platforms[:]
        new_commit(commit)
    db.put(commits)

create_commits = worker(GAE_QUEUE)(_create_commits)

@worker(GAE_QUEUE)
def update_user(login, info):
    user = User.get_or_insert(login)
    user.token = str(info['token'])
    user.gravatar = info['gravatar_id']
    user.name = info.get('name', '')
    user.emails = [info['email']]
    user.put()

@worker(GAE_QUEUE)
def create_slave(owner):
    slave = Slave()
    slave.owner = owner
    slave.token = hexlify(urandom(18))
    slave.put()
    return slave.key().id()

@worker(GAE_QUEUE, cache='slaves')
def get_slaves(next=None, n=101):
    more = False
    if next:
        next = db.Key.from_path('S', int(next))
        slaves = Slave.all().filter('__key__ >= ', next).fetch(n)
    else:
        slaves = Slave.all().fetch(n)
    if not slaves:
        return [], more
    if len(slaves) == n:
        more = slaves[-1].key().id()
    slaves = slaves[:n-1]
    return slaves, more

@worker(GAE_QUEUE, cache='slave')
def get_slave(slave_id, next=None, n=101):
    slave_id = int(slave_id)
    slave = Slave.get_by_id(slave_id)
    if not slave:
        return
    more = False
    if next:
        next = datetime.fromtimestamp(int(next) + 1)
        builds = Build.all().filter('s =', slave_id).filter(
            'd <=', next
            ).order('-d').fetch(n)
    else:
        builds = Build.all().filter('s =', slave_id).order('-d').fetch(n)
    if not builds:
        builds = []
    else:
        if len(builds) == n:
            more = builds[-1].d.strftime('%s')
        builds = builds[:n-1]
    pending = PendingJob.all().filter('s =', slave_id).get()
    return slave, builds, pending, more

@worker(GAE_QUEUE)
def change_slave_details(action, slave_id, user):
    slave = Slave.get_by_id(int(slave_id))
    if not slave:
        return
    if user != slave.owner:
        return 2
    if action == 'reset':
        slave.token = hexlify(urandom(18))
        slave.put()
        return 1
    if action.startswith('auth:'):
        repo = action[5:]
        if repo not in repos:
            return 2
        if slave.authorised_repos:
            if repo in slave.authorised_repos:
                return 1
            slave.authorised_repos.append(repo)
        else:
            slave.authorised_repos = [repo]
        slave.put()
        return 1
    if action.startswith('deauth:'):
        repo = action[7:]
        if repo not in repos:
            return 2
        if not slave.authorised_repos:
            return 1
        while repo in slave.authorised_repos:
            slave.authorised_repos.remove(repo)
        slave.put()
        return 1
    return 2

@worker(GAE_QUEUE)
def get_slave_job(repo, slave_id, token, uname, span=timedelta(seconds=1)):
    slave = Slave.get_by_id(slave_id)
    if (not slave) or (not secure_string_comparison(slave.token, token)):
        raise ValueError("Couldn't verify slave %s" % slave_id)
    if (not slave.authorised_repos) or (repo not in slave.authorised_repos):
        raise ValueError("Slave %s is not authorised for this repo." % slave_id)
    slave.last_seen = datetime.now()
    slave.recent_platform = uname
    platform = repo_cache[repo]._unames.get(uname)
    if not platform:
        slave.put()
        return
    prune = PendingJob.all().filter('d <=', datetime.now() - span).fetch(100)
    if prune:
        db.run_in_transaction(prune_pending_jobs, [ob.key() for ob in prune])
    review = Review.all().filter('n =', platform).filter('r =', repo).filter(
        'g =', 'build'
        ).order('d').get()
    commit = Commit.all().filter('n =', platform).filter('r =', repo).order(
        'd').get()
    if review and commit:
        if review.d >= commit.d:
            parent = review
        else:
            parent = commit
    elif review:
        parent = review
    elif commit:
        parent = commit
    else:
        slave.put()
        return
    result = []
    parent_key = parent.key()
    db.run_in_transaction(create_job, parent_key, result, slave_id, platform)
    if not result:
        slave.working = False
        slave.put()
        return
    slave.working = True
    slave.put()
    return parent.version

def prune_pending_jobs(keys):
    jobs = db.get(keys)
    parent_keys = [key.parent() for key in keys]
    parents = db.get(parent_keys)
    to_save = []; save = to_save.append
    for i in range(len(jobs)):
        platform = jobs[i].build_platform
        parent = parents[i]
        if not ((platform in parent.passed_builds) or
            (platform in parent.failed_builds) or
            (platform in parent.needed_builds)):
            parent.needed_builds.append(platform)
            save(parent)
    db.delete(keys)
    db.put(to_save)

def create_job(key, result, slave_id, platform):
    parent = db.get(key)
    if platform not in parent.needed_builds:
        return
    corrupted = 0
    if platform in parent.passed_builds:
        corrupted = 1
        while platform in parent.passed_builds:
            parent.passed_builds.remove(platform)
    if platform in parent.failed_builds:
        corrupted = 1
        while platform in parent.failed_builds:
            parent.failed_builds.remove(platform)
    parent.needed_builds.remove(platform)
    if corrupted:
        parent.put()
        return
    job = PendingJob(parent=parent)
    job.slave = slave_id
    job.build_platform = platform
    db.put([parent, job])
    result.append(1)

@worker(GAE_QUEUE)
def create_build(
    slave_id, token, repo, revision, uname, platform, executed, payload,
    timings, traceback, has_failure
    ):
    slave = Slave.get_by_id(slave_id)
    if (not slave) or (not secure_string_comparison(slave.token, token)):
        raise ValueError("Couldn't verify slave %s" % slave_id)
    if (not slave.authorised_repos) or (repo not in slave.authorised_repos):
        raise ValueError("Slave %s is not authorised for this repo." % slave_id)
    target = db.get(get_key_for_version(repo, revision))
    if not target:
        raise ValueError("Unknown revision %r for %s" % (revision, repo))
    build = Build()
    build.has_failure = has_failure
    build.executed = executed
    build.uname = uname
    build.build_platform = platform
    build.repo = repo
    build.slave = slave_id
    build.version = revision
    if traceback:
        build.build_phases = ''
    else:
        stderr, stdout = payload
        build_phases = []; add_phase = build_phases.append
        for idx, phase in enumerate(executed):
            if stdout[idx] or stderr[idx]:
                add_phase([phase, 1])
            else:
                add_phase([phase, 0])
        build.build_phases = encode_json(build_phases)
    slave.last_seen = datetime.now()
    slave.recent_platform = uname
    slave.working = False
    slave.jobs_done += 1
    db.put([build, slave])
    data = BuildData(key_name='d', parent=build)
    if traceback:
        data.traceback = True
        data.payload = payload
    else:
        data.payload = encode_json(payload)
    data.timings = timings
    db.put(data)
    db.run_in_transaction(
        update_build_target, target.key(), platform, has_failure
        )
    return build.key().id()

def update_build_target(target_key, platform, has_failure):
    target = db.get(target_key)
    while platform in target.needed_builds:
        target.needed_builds.remove(platform)
    if has_failure:
        target.has_failure = True
        if platform not in target.failed_builds:
            target.failed_builds.append(platform)
    else:
        if platform not in target.passed_builds:
            target.passed_builds.append(platform)
    to_save = [target]
    if target.kind() == 'R':
        if ((not target.needed_builds) and target.stage == 'build'):
            target.stage = 'built'
            base = db.get(target_key.parent())
            if int(target_key.name()) == base.latest:
                base.stage = 'built'
                to_save.append(base)
    db.put(to_save)

def get_key_for_version(repo, version, create_key=db.Key.from_path):
    if '/' in version:
        user, issue, id = version.split('/')
        parent = create_key('Q', '%s:%s:%s' % (repo, user, issue))
        return create_key('R', id, parent=parent)
    return create_key('G', '%s:%s' % (repo, version))

@worker(GAE_QUEUE, cache='builds')
def get_builds(repo, platform, version, next=None, n=101):
    more = False
    builds = Build.all()
    if repo:
        builds.filter('r =', repo)
    if platform:
        builds.filter('b =', unquote_plus(platform))
    if version:
        builds.filter('v =', version)
    if next:
        next = db.Key.from_path('B', int(next))
        builds = builds.filter('__key__ <=', next).order('-__key__').fetch(n)
    else:
        builds = builds.order('-__key__').fetch(n)
    if not builds:
        builds = []
    else:
        if len(builds) == n:
            more = builds[-1].key().id()
        builds = builds[:n-1]
    return builds, more

@worker(GAE_QUEUE)
def db_get(key):
    return db.get(key)

@worker(GAE_QUEUE, cache='build')
def get_build_data(build_id):
    build_id = int(build_id)
    build = Build.get_by_id(build_id)
    if not build:
        return
    build_key = build.key()
    data, target = db.get([
        db.Key.from_path('D', 'd', parent=build_key),
        get_key_for_version(build.repo, build.version)
        ])
    rebuild_state = repo_cache[build.repo]._unames.get(build.uname, None)
    if rebuild_state:
        if rebuild_state in target.needed_builds:
            rebuild_state = 1
        else:
            rebuild_state = 2
    return build, data, rebuild_state

def _rebuild(target_key, platform, result):
    target = db.get(target_key)
    if platform in target.needed_builds:
        return
    target.needed_builds.append(platform)
    while platform in target.passed_builds:
        target.passed_builds.remove(platform)
    while platform in target.failed_builds:
        target.failed_builds.remove(platform)
    if not target.failed_builds:
        target.has_failure = False
    target.put()
    result.append(1)

@worker(GAE_QUEUE)
def rebuild(repo, version, platform):
    target_key = get_key_for_version(repo, version)
    result = []
    db.run_in_transaction(_rebuild, target_key, platform, result)
    if result:
        return 1

@worker(GAE_QUEUE, cache='commits')
def get_commits(repo, version, user, failures_only, single, next, n=101):
    update_gravatars()
    more = False
    commits = Commit.all()
    if single:
        start = db.Key.from_path('G', '%s:%s' % (repo, version))
        end = db.Key.from_path('G', '%s:%sz' % (repo, version))
        commits = commits.filter('__key__ >= ', start).filter(
            '__key__ <=', end
            ).fetch(1)
    else:
        if repo:
            commits = commits.filter('r =', repo)
        if user:
            commits = commits.filter('u =', user)
        if failures_only:
            if failures_only == '0':
                commits = commits.filter('h =', False)
            else:
                commits = commits.filter('h =', True)
        if next:
            next = datetime.fromtimestamp(int(next) + 1)
            commits = commits.filter('d <=', next)
        commits = commits.order('-d').fetch(n)
    if commits:
        if len(commits) == n:
            more = commits[-1].d.strftime('%s')
        commits = commits[:n-1]
    builds = None
    if single and commits:
        version = commits[0].version
        builds = Build.all().filter('r =', repo).filter('v =', version).order(
            '-d'
            ).fetch(1000)
    return commits, builds, more

def update_gravatars():
    if NEEDED_GRAVATARS:
        changed = []
        for u in User.get_by_key_name(list(NEEDED_GRAVATARS)):
            if u and u.gravatar:
                GRAVATARS[u.key().name()] = u.gravatar
                changed.append(u)
        if changed:
            db.put(changed)

@worker(GAE_QUEUE, cache='activities')
def get_activities(
    repo, user, hide_commits, hide_slaves, next, n=101,
    get_key=db.Key.from_path
    ):
    update_gravatars()
    more = False
    submissions = Review.all()
    comments = Comment.all()
    if hide_commits:
        commits = []
    else:
        commits = Commit.all()
    if hide_slaves:
        builds = []
    else:
        builds = Build.all()
    if next:
        next = datetime.fromtimestamp(int(next) + 1)
    if repo:
        submissions = submissions.filter('r =', repo)
        comments = comments.filter('r =', repo)
        if not hide_commits:
            commits = commits.filter('r =', repo)
        if not hide_slaves:
            builds = builds.filter('r =', repo)
    if user:
        submissions = submissions.filter('u =', user)
        comments = comments.filter('u =', user)
        if not hide_commits:
            commits = commits.filter('u =', user)
        builds = []
    elif not hide_slaves:
        if next:
            builds = builds.filter('d <=', next)
        builds = builds.order('-d').fetch(n)
        if not builds:
            builds = []
    if not hide_commits:
        if next:
            commits = commits.filter('d <=', next)
        commits = commits.order('-d').fetch(n)
        if not commits:
            commits = []
    if next:
        submissions = submissions.filter('d <=', next)
        comments = comments.filter('d <=', next)
    submissions = submissions.order('-d').fetch(n)
    comments = comments.order('-d').fetch(n)
    activities = commits + builds + submissions + comments
    activities = sorted(activities, key=lambda i: i.d, reverse=1)
    if activities:
        if len(activities) >= n:
            more = activities[n-1].d.strftime('%s')
        activities = activities[:n-1]
    return activities, more

@worker(GAE_QUEUE, cache='review')
def get_review(repo, user, name, number, create_key=db.Key.from_path):
    update_gravatars()
    base_key = create_key('Q', "%s:%s:%s" % (repo, user, name))
    review_key = create_key('R', number, parent=base_key)
    base, review = db.get([base_key, review_key])
    builds = None
    if review:
        builds = Build.all().filter('r =', repo).filter(
            'v =', review.version).order('-d').fetch(1000)
    return base, review, builds

@worker(GAE_QUEUE, cache='reviews')
def get_reviews(
    repo, user, state, next, n=201, create_key=db.Key.from_path
    ):
    update_gravatars()
    more = False
    bases = ReviewBase.all()
    if user:
        bases = bases.filter('c =', user)
    if repo:
        bases = bases.filter('r =', repo)
    if state:
        bases = bases.filter('g =', state)
    if next:
        next = datetime.fromtimestamp(int(next) + 1)
        bases = bases.filter('m <=', next)
    bases = bases.order('-m').fetch(n)
    if not bases:
        return None, None, more
    if len(bases) == n:
        more = bases[-1].m.strftime('%s')
    bases = bases[:n-1]
    reviews = db.get(
        [create_key('R', str(base.latest), parent=base.key()) for base in bases]
        )
    _bases = {}
    for review, base in zip(reviews, bases):
        _bases[review.version] = base
    return reviews, _bases, more

def format_diff(diff, strip_first=1, add_bubbles=None):
    files = []; add_file = files.append
    if not diff:
        return None, files
    if strip_first:
        diff = diff.split('\n', 1)
        if len(diff) == 1:
            return None, files
        diff = diff[1]
    if not diff.strip():
        return None, files
    output = []; append = output.append
    parser = IteratorParser(diff.splitlines())
    counter = -1
    for line in parser:
        if line.startswith('diff --git '):
            if output:
                append('</table></div>')
            filename = line.split()[-1]
            binary = create = delete = end = 0
            new_filename = ''
            while 1:
                try:
                    line = parser.next()
                except StopIteration:
                    end = 1
                    break
                if line.startswith('new file mode'):
                    create = line
                elif line.startswith('Binary files'):
                    binary = 1
                elif line.startswith('deleted file mode'):
                    delete = line
                elif line.startswith('---'):
                    filename = line.split('--- ')[1]
                    if filename == '/dev/null':
                        filename = parser.next().split('+++ ', 1)[1]
                    else:
                        new_filename = parser.next().split('+++ ', 1)[1]
                        if filename == new_filename:
                            new_filename = ''
                    break
                elif line.startswith('diff --git'):
                    parser.push(line)
                    end = 1
                    break
            counter += 1
            _filename = escape(filename, 1)
            if new_filename:
                new_filename = ' &rarr; ' + escape(new_filename, 1)
            add_file(_filename)
            append(
                '<div class="patch"><table class="patch" cellspacing="0px"><tr>'
                '<td colspan="3" class="patch-title">'
                '<span class="patch-icon"><img src="/static/txt.png" /></span><span class="filename">%s%s</span></td></tr>'
                % (_filename, new_filename)
                )
            if binary:
                append('<tr><td colspan="3" class="binary"><pre>binary file not shown</pre></td></tr>')
                continue
            if end:
                append(
                    '<tr><td colspan="3" class="action"><pre>%s</pre></td></tr>'
                    % (create or delete)
                    )
                continue
            line = parser.next()
            in_delete = 0
        if line.startswith('@@ '):
            _, left, right, _ = line.split(' ', 3)
            left = abs(int(left.split(',')[0]))
            right = abs(int(right.split(',')[0]))
            append(
                '<tr><td class="line">...</td><td class="line">...</td>'
                '<td class="frag">%s</td>' % escape(line, 1)
            )
            line = parser.next()
        if (not in_delete) and line.startswith('-'):
            try:
                next = ori_next = parser.next()
            except StopIteration:
                next = None
            if next and next.startswith('+'):
                line = line[1:]
                next = next[1:]
                h1, d1, t1 = get_difference(line, next)
                h2, d2, t2 = get_difference(next, line)
                if d1:
                    first = (
                        escape(h1, 1) + '<strong>' + escape(d1, 1) + '</strong>' +
                        escape(t1, 1)
                        )
                else:
                    first = escape(line, 1)
                if d2:
                    second = (
                        escape(h2, 1) + '<strong>' + escape(d2, 1) + '</strong>' +
                        escape(t2, 1)
                        )
                else:
                    second = escape(next, 1)
                if add_bubbles:
                    left_bubble = (
                        '<a class="add-bubble" rel="%s-L%s">+ comment</a>'
                        % (counter, left)
                        )
                    right_bubble = (
                        '<a class="add-bubble" rel="%s-R%s">+ comment</a>'
                        % (counter, right)
                        )
                else:
                    left_bubble = right_bubble = ''
                append(
                    '<tr class="line">'
                    '<td class="line" id="L%sL%s">%s<a href="#L%sL%s">%s</a></td>'
                    '<td class="line"></td>'
                    '<td class="del"><pre>-%s</pre></td></tr>'
                    % (counter, left, left_bubble, counter, left, left, first)
                    )
                append(
                    '<tr class="line"><td class="line">%s</td>'
                    '<td class="line" id="L%sR%s"><a href="L%sR%s">%s</a></td>'
                    '<td class="add"><pre>+%s</pre></td></tr>'
                    % (right_bubble, counter, right, counter, right, right, second)
                    )
                left += 1
                right += 1
                continue
            elif next:
                parser.push(ori_next)
        if line.startswith('+'):
            type = 'add'
            _left = None
            _right = right
            right += 1
            in_delete = 0
        elif line.startswith('-'):
            type = 'del'
            _left = left
            _right = None
            left += 1
            in_delete = 1
        else:
            type = 'nrm'
            _left = left
            _right = right
            left += 1
            right += 1
            in_delete = 0
        if add_bubbles:
            if _left is not None:
                bubble = '%s-L%s' % (counter, _left)
            else:
                bubble = '%s-R%s' % (counter, _right)
            bubble = (
                '<a class="add-bubble" rel="%s">+ comment</a>' % bubble
                )
        else:
            bubble = ''
        if _left is not None:
            _left = (
                'id="L%sL%s">%s<a href="#L%sL%s">%s</a>'
                % (counter, _left, bubble, counter, _left, _left)
                )
        else:
            _left = '>%s' % bubble
        if _right is not None:
            _right = (
                'id="L%sR%s"><a href="#L%sR%s">%s</a>'
                % (counter, _right, counter, _right, _right)
                )
        else:
            _right = '>'
        append(
            '<tr><td class="line"%s</td><td class="line"%s</td>'
            '<td class="%s"><pre>%s</pre></td></tr>' % (
                _left, _right, type,
                line.replace("&", "&amp;").replace("<", "&lt;").replace(">", "&gt;").replace('"', "&quot;")
                )
            )
    append('</table></div>')
    return '\n'.join(output), files

@worker(GIT_QUEUE, cache='diff')
def get_diff(repo, revision):
    chdir(repo_paths[repo])
    return git(
        'diff-tree', '-M', '-p', '--no-prefix', revision,
        raise_error=True
        )

@worker(GIT_QUEUE, cache='diff:between')
def get_diff_between(repo, r1, r2):
    chdir(repo_paths[repo])
    return git(
        'diff-tree', '-M', '-p', '--no-prefix', r1, r2,
        raise_error=True
        )

@worker(GAE_QUEUE)
def add_comment(key, user, action, text, file, line):
    base_key = key.parent()
    return db.run_in_transaction(
        _add_comment, base_key, key, user, action, text, file, line
        )

def _add_comment(base_key, key, user, action, text, file, line):
    if base_key:
        base, target = db.get([base_key, key])
    else:
        target = db.get(key)
    kind = target.kind()
    now = datetime.now()
    if kind == 'R':
        retpath = '/review/%s/%s' % (target.repo, target.version)
        comment = Comment(parent=key)
        comment.repo = target.repo
        comment.version = target.version
        comment.user = user
        comment.text = text
        if file and line:
            comment.file = file
            comment.line = line
        elif action:
            if not is_repo_dev(target.repo, user):
                return
            if action == 'build':
                comment.stage = target.stage = base.stage = 'build'
            elif action == 'approve':
                if (target.stage != 'built') or (target.has_failure):
                    return
                comment.stage = target.stage = base.stage = 'approved'
            elif action == 'reject':
                comment.stage = target.stage = base.stage = 'rejected'
            elif action == 'applied':
                if target.stage != 'approved':
                    return
                comment.stage = target.stage = base.stage = 'applied'
        target.m = base.m = now
        target.has_comment = True
        if not base.cc:
            base.cc = [user]
        elif user not in base.cc:
            base.cc.append(user)
        db.put([comment, target, base])
    elif kind == 'G':
        retpath = '/commit/%s/%s' % (target.repo, target.version)
        if not text:
            return
        comment = Comment(parent=key)
        comment.text = text
        comment.repo = target.repo
        comment.version = target.version
        comment.user = user
        if file and line:
            comment.file = file
            comment.line = line
        target.m = now
        db.put([comment, target])
    else:
        return
    return "%s#comment-%s" % (retpath, comment.key().id())

@worker(GAE_QUEUE, cache='comments')
def get_comments(parent):
    _comments = Comment.all().ancestor(parent).order('-d').fetch(1000)
    if _comments:
        line_notes = []; add_line_note = line_notes.append
        comments = []; add_comment = comments.append
        for comment in _comments:
            if comment.file:
                add_line_note([
                    comment.file,
                    comment.line,
                    comment.user,
                    get_gravatar(comment.user) or '',
                    comment.d.strftime('%s'),
                    render_text(comment.text),
                    comment.key().id()
                    ])
            else:
                add_comment(comment)
        line_notes = encode_json(list(reversed(line_notes)))
        return comments, line_notes
    return None, None

# ------------------------------------------------------------------------------
# Datastore Models
# ------------------------------------------------------------------------------

class B(db.Model): # normal id
    repo = db.StringProperty(name='r')
    slave = db.IntegerProperty(name='s')
    version = db.StringProperty(name='v')
    build_platform = db.StringProperty(name='b')
    uname = db.StringProperty(name='u')
    executed = db.StringListProperty(name='e')
    build_phases = db.TextProperty('p')
    has_failure = db.BooleanProperty(name='h', default=False)
    d = db.DateTimeProperty(auto_now_add=True)

Build = B

class C(db.Model): # normal id; parent = Commit/Review
    user = db.StringProperty(name='u')
    text = db.TextProperty(name='t')
    repo = db.StringProperty(name='r')
    version = db.StringProperty(name='v')
    line = db.StringProperty(name='l')
    file = db.StringProperty(name='f')
    stage = db.StringProperty(name='g')
    d = db.DateTimeProperty(auto_now_add=True)

Comment = C

class D(db.Model): # normal id; parent = Build
    traceback = db.BooleanProperty(name='e', default=False)
    payload = db.TextProperty('p')
    timings = db.ListProperty(int, name='t', indexed=False)

BuildData = D

class G(db.Model): # id = <repo>:<git-revision>
    author = db.StringProperty(name='a')
    author_email = db.StringProperty(name='b')
    committer = db.StringProperty(name='c')
    committer_email = db.StringProperty(name='e')
    committed_timestamp = db.DateTimeProperty(name='t')
    repo = db.StringProperty(name='r')
    subject = db.TextProperty(name='s')
    version = db.StringProperty(name='v')
    needed_builds = db.StringListProperty(name='n')
    passed_builds = db.StringListProperty(name='p', indexed=False)
    failed_builds = db.StringListProperty(name='f', indexed=False)
    has_failure = db.BooleanProperty(name='h', default=False)
    user = db.StringProperty(name='u') # #unknown
    d = db.DateTimeProperty()
    m = db.DateTimeProperty()

Commit = G

class P(db.Model): # normal id; parent = Commit or Review
    slave = db.IntegerProperty(name='s')
    build_platform = db.StringProperty(name='b')
    d = db.DateTimeProperty(auto_now_add=True)

PendingJob = P

class Q(db.Model): # id = <repo>:<user>:<issue>
    cc = db.StringListProperty(name='c')
    latest = db.IntegerProperty(name='l', default=0)
    repo = db.StringProperty(name='r')
    m = db.DateTimeProperty(auto_now=True)
    stage = db.StringProperty(name='g', default='unset')

ReviewBase = Q

class R(db.Model): # id = incrementing integer; parent = ReviewBase
    subject = db.TextProperty(name='s')
    version = db.StringProperty(name='v')
    repo = db.StringProperty(name='r')
    upstream_revision = db.StringProperty(name='i')
    stage = db.StringProperty(name='g', default='unset')
    needed_builds = db.StringListProperty(name='n')
    passed_builds = db.StringListProperty(name='p', indexed=False)
    failed_builds = db.StringListProperty(name='f', indexed=False)
    has_failure = db.BooleanProperty(name='h', default=False)
    has_comment = db.BooleanProperty(name='j', default=False)
    user = db.StringProperty(name='u')
    d = db.DateTimeProperty()
    m = db.DateTimeProperty()
    revision = db.StringProperty(name='z')

Review = R

class S(db.Model): # normal id
    authorised_repos = db.StringListProperty(name='a')
    working = db.BooleanProperty(name='w', default=False)
    jobs_done = db.IntegerProperty(name='j', default=0)
    last_seen = db.DateTimeProperty(name='l')
    owner = db.StringProperty(name='o')
    recent_platform = db.StringProperty(name='r')
    token = db.StringProperty(name='t')

Slave = S

class U(db.Model): # key = github username
    name = db.StringProperty(name='n')
    emails = db.StringListProperty(name='e')
    gravatar = db.StringProperty(name='g')
    last_seen = db.DateTimeProperty(name='l', auto_now=True)
    token = db.StringProperty(name='t')
    d = db.DateTimeProperty(auto_now_add=True)

User = U

class Y(db.Model): # key = repo name
    maintainer = db.StringProperty(name='m')
    core_devs = db.StringListProperty(name='c')
    platforms = db.TextProperty(name='p')

Repo = Y

# ------------------------------------------------------------------------------
# Handlers
# ------------------------------------------------------------------------------

class BaseHandler(RequestHandler):

    cache = None
    title = None

    def get_current_user(self):
        return self.get_secure_cookie('login')

    def display(self, template, **kwargs):
        kwargs['render_text'] = render_text
        kwargs['get_gravatar'] = get_gravatar
        user = self.current_user
        if user:
            if user not in XSRF:
                XSRF[user] = HMAC(settings['xsrf_secret'], user).hexdigest()
            kwargs['xsrf_token'] = XSRF[user]
        else:
            kwargs['xsrf_token'] = None
        if 'dashboard_view' not in kwargs:
            kwargs['dashboard_view'] = 0
        if template:
            content = self.render_string(template + '.html', **kwargs)
        else:
            content = ''
        if 'return_content' in kwargs:
            return content
        self.render_site('site.html', content=content, **kwargs)

    def render_site(self, *args, **kwargs):
        if 'title' not in kwargs:
            kwargs['title'] = self.title
        if 'repo' in kwargs:
            if kwargs['repo'] not in repos:
                kwargs['repo'] = None
        else:
            kwargs['repo'] = None
        if 'errmsg' not in kwargs:
            kwargs['errmsg'] = None
        self.render(*args, **kwargs)

    def errmsg(self, errmsg, repo=None):
        self.render_site(
            'site.html', content='', errmsg=errmsg, repo=repo
            )

    def get(self):
        self.errmsg("Not implemented yet.")

    def is_repo_admin(self, repo_name):
        maintainer = repo_maintainers.get(repo_name, None)
        if not maintainer:
            return
        if self.current_user == maintainer:
            return True

    def is_repo_dev(self, repo_name):
        if self.is_repo_admin(repo_name):
            return True
        repo = repo_cache.get(repo_name, None)
        if repo and repo.core_devs:
            if self.current_user in repo.core_devs:
                return True

class RootHandler(BaseHandler):

    def get(self):
        self.redirect('/activity')

class RepoHandler(BaseHandler):

    title = 'repository'

    @async
    def get(self, repo):
        if repo not in repos:
            self.errmsg("No such repository found.")
            return
        repo_obj = repo_cache[repo]
        if repo_obj.platforms:
            try:
                platforms = decode_yaml(repo_obj.platforms)
                if not isinstance(platforms, dict):
                    platforms = None
            except Exception:
                platforms = None
        else:
            platforms = None
        slaves = yield get_authorised_slaves(repo)
        self.display(
            'repo', repo=repo, github=repos[repo], repo_obj=repo_obj,
            platforms=platforms, slaves=slaves
            )

    @auth()
    def post(self, repo):
        if repo not in repos:
            self.errmsg("No such repository found.")
            return
        if repo_maintainers[repo] != self.current_user:
            self.errmsg("You are not authorised to edit this repository.")
            return
        get = self.get_argument
        platforms = get('platforms', '')
        core_devs = get('core_devs', '')
        yield update_repo(repo, platforms, core_devs)
        self.redirect('/repo/%s' % repo)

class RepositoriesHandler(BaseHandler):

    title = 'repositories'

    def get(self):
        content = ["<h1>Repositories</h1><ul>"]; out = content.append
        for repo in sorted(repos):
            out('<li><a href="/repo/%s">%s</a></li>' % (repo, repo))
        out('</ul>')
        self.render_site('site.html', content='\n'.join(content))

class ActivityHandler(BaseHandler):

    title = 'activities'

    @async
    def get(self, repo=None, user=None):
        if not repos:
            self.errmsg('No repositories configured.')
            return
        if repo == '*':
            repo = None
        get = self.get_argument
        next = get('next', '')
        hide_commits = get('hide_commits', '')
        hide_slaves = get('hide_slaves', '')
        activities, more = yield get_activities(
            repo, user, hide_commits, hide_slaves, next
            )
        if not activities:
            self.errmsg("No activities found.", repo)
            return
        self.display(
            'activity', activities=activities, more=more, repo=repo, user=user,
            gravatars=GRAVATARS, md5=md5, hide_commits=hide_commits,
            hide_slaves=hide_slaves, decode_json=decode_json, repos=repos,
            render_text=render_text
            )

class DiffHandler(BaseHandler):

    @async
    def get(self, repo, r1, r2):
        r1 = r1.replace(';', '/')
        r2 = r2.replace(';', '/')
        diff = yield get_diff_between(repo, r1, r2)
        changes, files = format_diff(diff, strip_first=0)
        content = (
            '<h1>Diff &middot; %s &rarr; %s</h1>%s' % (r1, r2, changes)
            )
        self.render_site(
            'site.html', content=content, errmsg=None, title='diff'
            )

class ProfileHandler(BaseHandler):

    title = 'profile'

    @async
    def get(self, user=None, repo=None):
        if not user:
            user = self.current_user
            if not user:
                self.errmsg("No user found.")
                return
        activities, _ = yield get_activities(repo, user, None, None, None, n=31)
        if activities:
            activities = self.display(
                'activity', activities=activities, more=None, repo=repo,
                user=user, gravatars=GRAVATARS, md5=md5, hide_commits=None,
                hide_slaves=None, decode_json=decode_json, repos=repos,
                dashboard_view=1, return_content=1
                )
        commits = yield get_commits(
            repo, None, user, None, None, None, n=31
            )
        if repo:
            platforms = repo_cache[repo]._platforms
        else:
            platforms = None
        if commits and commits[0]:
            commits = self.display(
                'commits', commits=commits[0], commits_url='/commits',
                repos=repos, platforms=platforms, gravatars=GRAVATARS, md5=md5,
                decode_json=decode_json, dashboard_view=1, return_content=1,
                single=None, render_text=render_text, repo=repo
                )
        else:
            commits = None
        user_obj = yield db_get(db.Key.from_path('U', user))
        reviews = yield get_reviews(repo, user, None, None)
        if reviews and reviews[0]:
            reviews, bases, _ = reviews
            reviews = self.display(
                'reviews', reviews=reviews, more=None, repos=repos, repo=repo,
                bases=bases, gravatars=GRAVATARS, github=settings['github_account'],
                review_stages=review_stages, return_content=1, dashboard_view=1,
                render_text=render_text
                )
        else:
            reviews = None
        if repo:
            title = 'dashboard'
        else:
            title = 'profile'
        self.display(
            'profile', activities=activities, commits=commits, user=user,
            reviews=reviews, user_obj=user_obj, repo=repo, title=title
            )

class ReviewHandler(BaseHandler):

    title = 'review'

    @async
    def get(self, repo, user, name, number):
        repo, user, name = map(unquote_plus, (repo, user, name))
        base, review, builds = yield get_review(repo, user, name, number)
        if not review:
            self.errmsg("No such review found.", repo)
            return
        diff = yield get_diff_between(
            repo, review.upstream_revision, review.version
            )
        changes, files = format_diff(diff, strip_first=0, add_bubbles=self.current_user)
        comments, line_notes = yield get_comments(review)
        self.display(
            'review', review=review, repos=repos, repo=repo, base=base,
            gravatars=GRAVATARS, github=settings['github_account'],
            review_stages=review_stages, builds=builds, changes=changes,
            decode_json=decode_json, render_text=render_text,
            line_notes=line_notes, comments=comments, files=files,
            is_repo_dev=self.is_repo_dev(repo)
            )

class CommentHandler(BaseHandler):

    @auth()
    def post(self):
        get = self.get_argument
        login = get('login', self.current_user)
        review_id = get('review_id', '')
        if review_id:
            user, name, number = review_id.split('/')
            repo = get('repo')
            base = db.Key.from_path('Q', '%s:%s:%s' % (repo, user, name))
            key = db.Key.from_path('R', number, parent=base)
        else:
            key = db.Key(get('key'))
        action = get('action', '')
        file = get('file', '')
        line = get('line', '')
        text = get('text', '')
        if not (action or text):
            self.errmsg("Comment was blank.")
            return
        retpath = yield add_comment(key, login, action, text, file, line)
        if not retpath:
            self.errmsg("Invalid action.")
            return
        if retpath.startswith('/commit'):
            invalidate('comments', 'activities', 'commits')
        else:
            invalidate('comments', 'activities', 'review', 'reviews')
        self.redirect(retpath)

class ReviewsHandler(BaseHandler):

    title = 'reviews'

    @async
    def get(self, repo=None, user=None):
        get = self.get_argument
        next = get('next', '')
        state = get('state', '')
        if repo == '*':
            repo = None
        reviews = yield get_reviews(repo, user, state, next)
        if not reviews:
            self.errmsg("No matching reviews found.", repo)
            return
        reviews, bases, more = reviews
        more_url_base = '/reviews'
        if repo:
            more_url_base += '/' + quote(repo)
        elif user:
            more_url_base += '/*'
        if user:
            more_url_base += '/' + quote(user)
        url_base = more_url_base
        if state:
            more_url_base += '?state=%s&' % state
        else:
            more_url_base += '?'
        self.display(
            'reviews', reviews=reviews, more=more, repos=repos, repo=repo,
            bases=bases, gravatars=GRAVATARS, github=settings['github_account'],
            review_stages=review_stages, render_text=render_text,
            more_url_base=more_url_base, url_base=url_base, state=state
            )

    @auth(xsrf=False)
    def post(self):

        get = self.get_argument
        patch_name = get('name')
        if not valid_patch_name(patch_name):
            self.write("Invalid characters in the patch name: %s" % patch_name)
            return

        repo = get('repo')
        if repo not in repos:
            self.write("Unknown repo: %s" % repo)
            return

        user = get('login')
        patch = get('patch')
        upstream = get('upstream')
        message = get('message')
        revision = get('revision')

        cc = get('cc', '')
        if cc:
            cc = set(decode_json(cc))
        else:
            cc = set()

        if user not in cc:
            cc.add(user)

        review = yield get_review_object(repo, user, patch_name, revision)
        if not review:
            self.write("Couldn't create new review object.")
            return

        base, review = review
        if base == 1:
            self.write(
                "Sorry, your submission already exists at /review/%s/%s"
                % (repo, review)
                )
            return

        patch_number = review.key().name()

        review_id = '%s/%s/%s' % (user, patch_name, patch_number)
        review_url = '%s/%s' % (repo, review_id)

        fd, patch_file = mkstemp('-review-patch')
        write(fd, patch.encode('utf-8'))
        close(fd)

        yield apply_patch(repo, review_id, upstream, patch_file)

        now = datetime.now()
        review.d = review.m = now
        review.subject = message
        review.repo = repo
        review.upstream_revision = upstream
        review.needed_builds = repo_cache[repo]._platforms[:]
        review.user = user
        review.version = review_id

        if is_repo_dev(repo, user):
            review.stage = 'build'
        else:
            review.stage = 'pending'

        yield update_and_email_review(base, review, cc)

        self.write('OK %s' % review_url)
        remove(patch_file)
        invalidate('review', 'reviews', 'activities')

class PreviewHandler(BaseHandler):

    def post(self):
        text = self.get_argument('text', '')
        if not text:
            self.write('')
            return
        self.write(render_text(text))

class CommitsHandler(BaseHandler):

    title = 'commits'

    @async
    def get(self, repo=None, version=None, user=None, single=0):
        get = self.get_argument
        next = get('next', '')
        failures_only = get('failures_only', '')
        if repo == '*':
            repo = None
        if version == '*':
            version = None
        if repo and version:
            single = 1
            title = 'commit'
        else:
            title = self.title
        revision_data = yield get_commits(
            repo, version, user, failures_only, single, next
            )
        if not revision_data:
            self.errmsg("Sorry, no data found.", repo)
            return
        commits, builds, more = revision_data
        if not commits:
            self.errmsg("No commits found.", repo)
            return
        commits_url = '/commits'
        if repo:
            commits_url += escape(quote('/%s' % repo), 1)
        changes = None
        files = []
        platforms = []
        if repo:
            platforms = repo_cache[repo]._platforms
        line_notes = None
        comments = None
        if single:
            if commits:
                diff = yield get_diff(repo, commits[0].version)
                changes, files = format_diff(diff, add_bubbles=self.current_user)
                comments, line_notes = yield get_comments(commits[0])
        self.display(
            'commits', commits=commits, more=more, builds=builds, single=single,
            failures_only=failures_only, version=version, user=user,
            commits_url=commits_url, repos=repos, repo=repo, platforms=platforms,
            gravatars=GRAVATARS, md5=md5, decode_json=decode_json, title=title,
            changes=changes, render_text=render_text, files=files,
            line_notes=line_notes, comments=comments
            )

class BuildsHandler(BaseHandler):

    title = 'builds'

    @async
    def get(self, repo=None, platform=None, version=None):
        if repo == '*':
            repo = None
        if platform == '*':
            platform = None
        next = self.get_argument('next', '')
        builds, more = yield get_builds(repo, platform, version, next)
        if not builds:
            self.errmsg("No builds found.", repo)
            return
        if repo and platform and version and builds:
            if len(builds) == 1:
                self.redirect('/build/%s' % builds[0].key().id())
                return
        self.display('builds', builds=builds, more=more, repo=repo, repos=repos)

class BuildHandler(BaseHandler):

    title = 'build'

    @async
    def get(self, build_id):
        build_data = yield get_build_data(build_id)
        if not build_data:
            self.errmsg("No records found for build %s" % build_id)
            return
        build, data, rebuild_state = build_data
        traceback = timings = stderr = stdout = None
        if data:
            if data.traceback:
                traceback = data.payload
            else:
                timings = data.timings
                stderr, stdout = decode_json(data.payload)
        is_repo_dev = self.is_repo_dev(build.repo)
        self.display(
            'build', build_id=build_id, build=build, traceback=traceback,
            timings=timings, stdout=stdout, stderr=stderr, data=data,
            rebuild_state=rebuild_state, unames=repo_cache[build.repo]._unames,
            repo=build.repo, is_repo_dev=is_repo_dev
            )

    @async
    def post(self, has_failure=False):
        get = self.get_argument
        revision = get('revision')
        uname = get('uname')
        repo = get('repo')
        slave_id = get('slave_id')
        token = get('token')
        data = get('data')
        try:
            slave_id = int(slave_id)
        except Exception:
            self.write("Invalid slave id: %r" % get('slave'))
            return
        try:
            data = decode_json(data)
        except Exception, err:
            self.write("Error decoding build data: %s" % err)
            return
        if 'traceback' in data:
            traceback = 1
            payload = data['traceback']
            timings = []
            executed = []
            has_failure = True
        else:
            traceback = 0
            executed = data['executed']
            stderr = []; add_stderr = stderr.append
            stdout = []; add_stdout = stdout.append
            timings = []; add_timing = timings.append
            payload = [stderr, stdout]
            for item in executed:
                add_timing(data['%s|time' % item])
                add_stderr(data.get('%s|stderr' % item, None))
                out = data.get('%s|stdout' % item, None)
                add_stdout(out)
                if out:
                    has_failure = True
        platform = repo_cache[repo]._unames.get(uname)
        build = yield create_build(
            slave_id, token, repo, revision, uname, platform, executed, payload,
            timings, traceback, has_failure
            )
        self.write('OK %s' % build)
        invalidate('build', 'builds', 'activities', 'slave', 'slaves', 'commits', 'commit')

class JobHandler(BaseHandler):

    @async
    def get(self):
        self.set_header('Content-Type', 'text/plain')
        get = self.get_argument
        uname = get('uname')
        repo = get('repo')
        slave_id = get('slave_id')
        token = get('token')
        try:
            slave_id = int(slave_id)
        except Exception:
            self.write("Invalid slave id: %r" % slave_id)
            return
        try:
            job = yield get_slave_job(repo, slave_id, token, uname)
        except ValueError, err:
            self.write(repr(err))
            return
        self.write('OK ')
        if job:
            self.write(job)
        else:
            self.write('')
        invalidate('slave', 'slaves')

class ChartsHandler(BaseHandler):
    pass

class LoginHandler(BaseHandler):

    title = 'login'

    def get(self):
        self.display('login')

    @async
    def post(self):
        login = self.get_argument('login', "")
        token = self.get_argument('token', "")
        info = yield get_github_user_info(login, token)
        if not info:
            self.display('login', errmsg="Invalid Login.")
            return
        yield update_user(login, info)
        self.set_secure_cookie('login', login)
        self.redirect('/')

class LogoutHandler(BaseHandler):

    def get(self):
        self.clear_cookie('login')
        return_to = self.get_argument('return_to', '')
        if return_to:
            self.redirect(return_to)
        else:
            self.redirect('/')

class SlavesHandler(BaseHandler):

    title = 'slaves'

    @async
    def get(self):
        next = self.get_argument('next', '')
        slaves, more = yield get_slaves(next)
        self.display('slaves', slaves=slaves, more=more)

    @auth()
    def post(self):
        slave_id = yield create_slave(self.current_user)
        invalidate('slaves')
        self.redirect('/slave/%s' % slave_id)

class SlaveHandler(BaseHandler):

    title = 'slave'

    @async
    def get(self, slave_id):
        next = self.get_argument('next', '')
        slave_data = yield get_slave(slave_id, next)
        if not slave_data:
            self.errmsg("No records found for slave %s" % slave_id)
            return
        slave, builds, pending, more = slave_data
        show_token = self.current_user == slave.owner
        self.display(
            'slave', slave_id=slave_id, slave=slave, show_token=show_token,
            builds=builds, more=more, pending=pending,
            repos=maintainer_repos.get(self.current_user, None)
            )

    @auth()
    def post(self, slave_id):
        action = self.get_argument('action', '')
        retcode = yield change_slave_details(
            action, slave_id, self.current_user
            )
        if not retcode:
            self.errmsg("Couldn't find a record for slave %s." % slave_id)
            return
        if retcode == 2:
            self.errmsg("You're not authorised for this action.")
            return
        invalidate('slave', 'slave:auth', 'slaves')
        self.redirect('/slave/%s' % slave_id)

class PostReceiveHandler(BaseHandler):

    @async
    def post(self, repo):
        if repo not in repos:
            self.errmsg("No such repo configured.")
            return
        commits = yield get_new_commits(repo, repo_commits[repo])
        yield create_commits(repo, commits)
        self.write('OK')
        invalidate('commits', 'activities')

    get = post

class RebuildHandler(BaseHandler):

    @auth()
    def post(self):
        get = self.get_argument
        repo = get('repo')
        version = get('version')
        platform = get('platform')
        build_id = get('build_id')
        if platform not in repo_cache[repo]._platforms:
            self.errmsg("%s is not supported atm." % platform)
            return
        yield rebuild(repo, version, platform)
        invalidate('build')
        self.redirect('/build/%s' % build_id)

# ------------------------------------------------------------------------------
# Main Runner
# ------------------------------------------------------------------------------

def main(argv=None):

    argv = argv or sys.argv[1:]
    op = OptionParser(usage="Usage: %prog [config.yaml]", version="0.1")

    op.add_option('--dev', action='store_true', help="enable dev mode")
    options, args = op.parse_args(argv)

    if args:
        config_path = args[0]
        config_file = open(config_path, 'rb')
        config_data = config_file.read()
        config_file.close()
        config = decode_yaml(config_data)
        if not config:
            print "ERROR: Couldn't find any config data in %s" % config_path
            sys.exit(1)
    else:
        config = {}

    settings.update(config)
    cwd = realpath(getcwd())

    if options.dev:
        settings['debug'] = True
        cwd = dirname(realpath(__file__)) # @@ to support autoreload

    for key in ['static_path', 'template_path', 'var_path']:
        path = join(cwd, settings[key])
        if not isdir(path):
            print "ERROR: Please create the %s: %s" % (key, path)
            sys.exit(1)
        settings[key] = path

    repo_home = settings['repo_home'] = join(settings['var_path'], 'repos')
    if not isdir(repo_home):
        print "ERROR: Please create %s" % repo_home
        sys.exit(1)

    logging.getLogger().setLevel(logging.INFO)
    enable_pretty_logging()

    github_account = settings['github_account']

    _repos = settings['repos']
    if _repos:
        for repo in _repos:
            repos[repo] = tuple(_repos[repo]['github'])
            maintainer = _repos[repo]['maintainer']
            repo_maintainers[repo] = maintainer
            if maintainer not in maintainer_repos:
                maintainer_repos[maintainer] = []
            maintainer_repos[maintainer].append(repo)
            repo_paths[repo] = repo_path = join(repo_home, repo)
            if options.dev:
                continue
            chdir(repo_home)
            if not isdir(repo_path):
                review_url = 'git@github.com:%s/%s.git' % (github_account, repo)
                git('clone', review_url, out=True)
            chdir(repo_path)
            if not git('config', 'remote.upstream.url', exit_on_error=False):
                upstream_url = 'https://github.com/%s/%s.git' % repos[repo]
                git('remote', 'add', 'upstream', upstream_url)

    for values in maintainer_repos.values():
        values.sort()

    application = Application([
        (r"/comment", CommentHandler),
        (r"/repositories", RepositoriesHandler),
        (r"/repo/([^/]*)", RepoHandler),
        (r"/dashboard/([^/]*)/(.*)", ProfileHandler),
        (r"/profile/([^/]*)", ProfileHandler),
        (r"/charts", ChartsHandler),
        (r"/builds/([^/]*)", BuildsHandler),
        (r"/builds/([^/]*)/([^/]*)", BuildsHandler),
        (r"/builds/([^/]*)/([^/]*)/(.*)", BuildsHandler),
        (r"/builds", BuildsHandler),
        (r"/build/([0-9]+)", BuildHandler),
        (r"/build", BuildHandler),
        (r"/review/([^/]*)/([^/]*)/([^/]*)/([^/]*)", ReviewHandler),
        (r"/reviews/([^/]*)/([^/]*)/([^/]*)", ReviewsHandler),
        (r"/reviews/([^/]*)/([^/]*)", ReviewsHandler),
        (r"/reviews/([^/]*)", ReviewsHandler),
        (r"/reviews", ReviewsHandler),
        (r"/commits/([^/]*)/([^/]*)/([^/]*)", CommitsHandler),
        (r"/commit/([^/]*)/([0-9a-z]*)", CommitsHandler),
        (r"/commits/([^/]*)", CommitsHandler),
        (r"/commits", CommitsHandler),
        (r"/job", JobHandler),
        (r"/logout", LogoutHandler),
        (r"/login", LoginHandler),
        (r"/slave/([0-9]+)", SlaveHandler),
        (r"/slaves", SlavesHandler),
        (r"/activity/([^/]*)", ActivityHandler),
        (r"/activity/([^/]*)/(.*)", ActivityHandler),
        (r"/activity", ActivityHandler),
        (r"/post-receive/([^/]*)", PostReceiveHandler),
        (r"/rebuild", RebuildHandler),
        (r"/diff/([^/]*)/([^/]*)/([^/]*)", DiffHandler),
        (r"/preview", PreviewHandler),
        (r"/", RootHandler),
    ], **settings)

    port = settings['port']
    http_server = HTTPServer(application)
    http_server.listen(port)

    set_max_connections(50)
    def cache_init(ipc=settings['redis_socket_file']):
        return Redis(unix_socket=ipc)

    global cache
    cache = cache_init

    for queue in [URL_QUEUE, GIT_QUEUE, GAE_QUEUE]:
        start_new_thread(threaded_worker_dispatcher, (queue,))

    logging.info("Connecting to App Engine Server at %s" % settings['gae_host'])
    init_appengine(
        settings['gae_app_id'], settings['gae_host'],
        settings['gae_remote_key'], settings['gae_secure']
        )

    if repos:
        repo_keys = repos.keys()
        to_save = []; save = to_save.append
        for key, repo in zip(repo_keys, Repo.get_by_key_name(repo_keys)):
            if not repo:
                repo = Repo(key_name=key)
            repo.maintainer = repo_maintainers[key]
            save(repo)
        db.put(to_save)
        for repo in to_save:
            setup_repo_platforms(repo)

    for repo in repos:
        logging.info("Storing commit data for %s" % repo)
        commit = Commit.all().filter('r =', repo).order('-d').get()
        if commit:
            repo_commits[repo] = commit.version
        else:
            commits = _get_new_commits(repo, 'upstream/master^')
            _create_commits(repo, commits)

    logging.info("The git review server is listening on port %d ..." % port)
    Loop.start()

# ------------------------------------------------------------------------------
# Self Runner
# ------------------------------------------------------------------------------

if __name__ == '__main__':
    main()
